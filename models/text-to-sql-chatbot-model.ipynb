{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q transformers==4.36.0 datasets==2.16.0 peft==0.7.0 accelerate==0.25.0 torch==2.1.0 sentencepiece==0.1.99","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:39:10.498909Z","iopub.execute_input":"2025-11-10T16:39:10.499646Z","iopub.status.idle":"2025-11-10T16:39:14.090741Z","shell.execute_reply.started":"2025-11-10T16:39:10.499618Z","shell.execute_reply":"2025-11-10T16:39:14.089953Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq\n)\nfrom peft import get_peft_model, LoraConfig, TaskType\n\nclass Config:\n    BASE_MODEL = \"Salesforce/codet5p-220m\"\n    LORA_R = 8\n    LORA_ALPHA = 16\n    LORA_DROPOUT = 0.1\n    EPOCHS = 2\n    BATCH_SIZE = 8\n    LEARNING_RATE = 3e-4\n    MAX_LENGTH = 512\n    DATASET_NAME = \"b-mc2/sql-create-context\"\n    TRAIN_SAMPLES = 10000\n    OUTPUT_DIR = \"/kaggle/working/fine_tuned_text2sql_codet5\"\n    GRADIENT_ACCUMULATION = 2\n\nconfig = Config()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:39:35.310840Z","iopub.execute_input":"2025-11-10T16:39:35.311838Z","iopub.status.idle":"2025-11-10T16:39:35.317207Z","shell.execute_reply.started":"2025-11-10T16:39:35.311797Z","shell.execute_reply":"2025-11-10T16:39:35.316543Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset = load_dataset(config.DATASET_NAME, split=\"train\")\ndataset = dataset.shuffle(seed=42).select(range(config.TRAIN_SAMPLES))\ndataset = dataset.train_test_split(test_size=0.1, seed=42)\ntrain_dataset, eval_dataset = dataset[\"train\"], dataset[\"test\"]\n\ntokenizer = AutoTokenizer.from_pretrained(config.BASE_MODEL)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    config.BASE_MODEL,\n    torch_dtype=torch.float32,\n    device_map=\"auto\"\n)\n\nlora_config = LoraConfig(\n    r=config.LORA_R,\n    lora_alpha=config.LORA_ALPHA,\n    target_modules=[\"SelfAttention.q\", \"SelfAttention.v\"],\n    lora_dropout=config.LORA_DROPOUT,\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:40:02.017041Z","iopub.execute_input":"2025-11-10T16:40:02.017314Z","iopub.status.idle":"2025-11-10T16:40:05.788374Z","shell.execute_reply.started":"2025-11-10T16:40:02.017294Z","shell.execute_reply":"2025-11-10T16:40:05.787797Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb580c641a2a43c7aa700cc1a27800e9"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:12.868569Z","iopub.execute_input":"2025-11-10T16:41:12.869152Z","iopub.status.idle":"2025-11-10T16:41:12.924945Z","shell.execute_reply.started":"2025-11-10T16:41:12.869128Z","shell.execute_reply":"2025-11-10T16:41:12.924200Z"}},"outputs":[{"name":"stdout","text":"trainable params: 589,824 || all params: 223,471,872 || trainable%: 0.2639365727423629\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [f\"Schema: {ctx}\\nQuestion: {q}\\nSQL:\" for ctx, q in zip(examples[\"context\"], examples[\"question\"])]\n    targets = examples[\"answer\"]\n    model_inputs = tokenizer(inputs, max_length=config.MAX_LENGTH, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=config.MAX_LENGTH, truncation=True, padding=\"max_length\")\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:13.254365Z","iopub.execute_input":"2025-11-10T16:41:13.255042Z","iopub.status.idle":"2025-11-10T16:41:13.261060Z","shell.execute_reply.started":"2025-11-10T16:41:13.255011Z","shell.execute_reply":"2025-11-10T16:41:13.260159Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\neval_dataset = eval_dataset.map(preprocess_function, batched=True, remove_columns=eval_dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:13.610997Z","iopub.execute_input":"2025-11-10T16:41:13.611275Z","iopub.status.idle":"2025-11-10T16:41:17.658770Z","shell.execute_reply.started":"2025-11-10T16:41:13.611250Z","shell.execute_reply":"2025-11-10T16:41:17.657968Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d0017e0290a4268b67ab8a3d25c98ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f868d30745ee4c7aabe103605eb2b847"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=config.OUTPUT_DIR,\n    num_train_epochs=config.EPOCHS,\n    per_device_train_batch_size=config.BATCH_SIZE,\n    per_device_eval_batch_size=config.BATCH_SIZE,\n    gradient_accumulation_steps=config.GRADIENT_ACCUMULATION,\n    learning_rate=config.LEARNING_RATE,\n    weight_decay=0.01,\n    logging_dir=f\"{config.OUTPUT_DIR}/logs\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    fp16=False,\n    bf16=False,\n    predict_with_generate=True,\n    generation_max_length=config.MAX_LENGTH,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:17.659962Z","iopub.execute_input":"2025-11-10T16:41:17.660188Z","iopub.status.idle":"2025-11-10T16:41:17.665180Z","shell.execute_reply.started":"2025-11-10T16:41:17.660171Z","shell.execute_reply":"2025-11-10T16:41:17.664446Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:18.311813Z","iopub.execute_input":"2025-11-10T16:41:18.312339Z","iopub.status.idle":"2025-11-10T16:41:18.315816Z","shell.execute_reply.started":"2025-11-10T16:41:18.312315Z","shell.execute_reply":"2025-11-10T16:41:18.314994Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()\ntrainer.save_model(config.OUTPUT_DIR)\ntokenizer.save_pretrained(config.OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:41:30.985455Z","iopub.execute_input":"2025-11-10T16:41:30.985733Z","iopub.status.idle":"2025-11-10T17:21:37.511671Z","shell.execute_reply.started":"2025-11-10T16:41:30.985713Z","shell.execute_reply":"2025-11-10T17:21:37.510885Z"}},"outputs":[{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1124' max='1124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1124/1124 40:03, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>5.574900</td>\n      <td>5.102997</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>5.204700</td>\n      <td>5.098799</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine_tuned_text2sql_codet5/tokenizer_config.json',\n '/kaggle/working/fine_tuned_text2sql_codet5/special_tokens_map.json',\n '/kaggle/working/fine_tuned_text2sql_codet5/vocab.json',\n '/kaggle/working/fine_tuned_text2sql_codet5/merges.txt',\n '/kaggle/working/fine_tuned_text2sql_codet5/added_tokens.json',\n '/kaggle/working/fine_tuned_text2sql_codet5/tokenizer.json')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"test_cases = [\n    {\n        \"schema\": 'CREATE TABLE sales (region TEXT, revenue INTEGER, year INTEGER)',\n        \"question\": \"Show total revenue by region for 2024.\"\n    },\n    {\n        \"schema\": 'CREATE TABLE customers (id INTEGER, name TEXT, city TEXT)',\n        \"question\": \"List all customers from Delhi.\"\n    }\n]\n\nfor test in test_cases:\n    prompt = f\"Schema: {test['schema']}\\nQuestion: {test['question']}\\nSQL:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model.device)\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=128, num_beams=4)\n    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(f\"Q: {test['question']}\\nSQL: {sql_query}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T17:21:37.512722Z","iopub.execute_input":"2025-11-10T17:21:37.513300Z","iopub.status.idle":"2025-11-10T17:21:39.038803Z","shell.execute_reply.started":"2025-11-10T17:21:37.513281Z","shell.execute_reply":"2025-11-10T17:21:39.038054Z"}},"outputs":[{"name":"stdout","text":"Q: Show total revenue by region for 2024.\nSQL: SELECT COUNT(region) FROM sales WHERE revenue = \"2024\" AND year = 2024\n\nQ: List all customers from Delhi.\nSQL: SELECT id FROM customers WHERE name = \"Delhi\" AND city = \"Delhi\"\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!cd /kaggle/working && zip -r fine_tuned_text2sql_codet5.zip fine_tuned_text2sql_codet5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T17:28:45.322049Z","iopub.execute_input":"2025-11-10T17:28:45.322339Z","iopub.status.idle":"2025-11-10T17:28:46.709142Z","shell.execute_reply.started":"2025-11-10T17:28:45.322317Z","shell.execute_reply":"2025-11-10T17:28:46.708423Z"}},"outputs":[{"name":"stdout","text":"  adding: fine_tuned_text2sql_codet5/ (stored 0%)\n  adding: fine_tuned_text2sql_codet5/merges.txt (deflated 54%)\n  adding: fine_tuned_text2sql_codet5/vocab.json (deflated 59%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/ (stored 0%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/merges.txt (deflated 54%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/vocab.json (deflated 59%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/special_tokens_map.json (deflated 97%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/tokenizer_config.json (deflated 94%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/training_args.bin (deflated 51%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/rng_state.pth (deflated 25%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/trainer_state.json (deflated 53%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/scheduler.pt (deflated 56%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/tokenizer.json (deflated 72%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/adapter_config.json (deflated 50%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/README.md (deflated 66%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-562/optimizer.pt (deflated 8%)\n  adding: fine_tuned_text2sql_codet5/special_tokens_map.json (deflated 97%)\n  adding: fine_tuned_text2sql_codet5/tokenizer_config.json (deflated 94%)\n  adding: fine_tuned_text2sql_codet5/adapter_model.safetensors (deflated 7%)\n  adding: fine_tuned_text2sql_codet5/training_args.bin (deflated 51%)\n  adding: fine_tuned_text2sql_codet5/tokenizer.json (deflated 72%)\n  adding: fine_tuned_text2sql_codet5/adapter_config.json (deflated 50%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/ (stored 0%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/merges.txt (deflated 54%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/vocab.json (deflated 59%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/special_tokens_map.json (deflated 97%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/tokenizer_config.json (deflated 94%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/adapter_model.safetensors (deflated 7%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/training_args.bin (deflated 51%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/rng_state.pth (deflated 25%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/trainer_state.json (deflated 60%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/scheduler.pt (deflated 55%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/tokenizer.json (deflated 72%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/adapter_config.json (deflated 50%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/README.md (deflated 66%)\n  adding: fine_tuned_text2sql_codet5/checkpoint-1124/optimizer.pt (deflated 8%)\n  adding: fine_tuned_text2sql_codet5/README.md (deflated 66%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}